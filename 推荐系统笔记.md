第一章：概述
1.每一次推荐都是结合用户，物品，场景的特征去进行预测
**Score = f(User, Item, Context)**
![描述](img/1.png)

工业视角：
2.由于不可能给每个用户进行预测所以推荐系统分成了三层
![描述](img/2.png)
	
 	1.召回：从所有物品库中通过协同过滤等方法粗筛出数量较多的物品
	2.排序：使用模型，也就是上面的公式对召回的候选集的物品进行预测来计算得分
	3.重排：由于排序后可能推荐的物品都是同一类物品，考虑到多样性，新颖性，公平性，对排序适当调整，插入别的物品

宏观视角：
3.工业上完美不代表现实中完美，推荐系统是一个生态，有三个支点：**用户与创作者、内容、平台**

用户与创作者：需要推荐物品的同时也会生产物品
	生产方式分为3类：UGC（普通用户生产，质量参差不齐），PGC（专业用户生产，质量好），AIGC（ai生产，质量）

内容：是推荐系统真正要去分发的物品，不光要发受欢迎的也要分发有潜力的物品

平台：推荐系统的协调者，不光要提升用户满意度，也要维护平台的内容质量，防止标题党
![描述](img/3.png)

召回又分为：
	**协同过滤**
	**向量召回**
	**序列召回**

第二章：召回
1.协同过滤
通过用户的历史行为数据（如评分、点击、购买记录）来计算用户和用户or物品和物品之间的相似度来召回
分为两类：
	一.基于用户（UCF）
 	具有相似历史行为的用户，未来偏好也相似
   	![描述](img/d35ffe5e-2ad4-4c47-af3d-2bec6ea013dc.png)
	实现分为两步：
	1.用户相似度：假设用户u,v分别对应nu,nv
 		杰卡德相似系数:![描述](img/66d865b8-8f38-4e1a-a4cc-47ecd8f5d135.png) 适合只有行为没有评分的数据集
		余弦相似度:![描述](img/fffd7e65-97df-42e0-83f9-772408c31a16.png) 
  		皮尔逊相关系数:![描述](img/034f4a6a-45d1-4b47-a69c-34df9dfbcaad.png) 有评分就用这个
	2.推荐候选物品：
 		简单加权平均：所有用户都计算 
   		考虑评分偏置的版本：减少评分习惯的影响
	 	基于物品倒排表的优化：只计算有交集的用户
	二.基于物品（ICF）
	喜欢某个物品的用户往往也会对相似的物品感兴趣
	![描述](img/5e22c0de-460d-43da-9db0-0164b6ec2290.png)
 	实现也分为两步：
  	1.物品相似度：
   		与用户类似，排除掉无用户交集的物品来计算余弦相似度
	2.推荐候选物品
 		无评分的话就用相似度来计算分数
   		有评分就用皮尔逊相关系数
	特殊的：
	一.swing算法
 	如果多个用户在其他共同购买行为较少的情况下，同时购买了同一对物品，那么这对物品之间的关联性就更可信
  	分为两步：
   	1.构建用户-物品二部图：
		用户与发生过操作的物品进行连线，形成一个连线图
  	2.计算任意一对物品的相似度
   		ui和uj表示与物品ij有过交互的用户集合，iu表示用户u交互过的物品集合
	 	先找到同时与物品ij相连的用户集合ui ∩ uj
   		再对集合中的每一对用户统计其他共同购买的行为，如果其他物品共同购买的行为少的话证明他们在ij上的购买行为更具特异性，从而为ij贡献更高的相似度得分
   		为降低活跃用户对计算结果的影响，引入用户权重
	 	![描述](img/QQ_1758389942289.png)
   	二.Surprise 算法
	这是上面算法的优化，从类别、商品和聚类三个层面来衡量互补相关性：
  	1.类别层面：
   		计算类与类之间的相关性
   		![描述](img/616fdfb2-db3c-4474-9d13-28b280f96414.png)
	2.商品层面：
 		重点考虑两个因素：购买顺序的重要性，时间间隔的影响
   		![描述](img/f018df90-e1a4-40dc-8c6a-634d851ad1a7.png)
	3.聚类层面：
 		用标签传播算法聚类，邻居关系通过Swing算法计算，边权重即为Swing分数
   	4.线性组合：
		把2，3线性组合融合不同层面的信息
  		![描述](img/9bfc76ca-46aa-42a4-8a29-9ae282ba7f59.png)
	二.矩阵分解
	因为协同过滤有时候当评分数据非常稀疏时，很难找到足够的相似用户或物品。所以用矩阵分解
	核心建立于两个假设：
		低秩假设：矩阵可能只受少数几个隐含因素影响，可以降秩
		隐向量假设：可以用一个包含这些隐含因素的向量来表示用户和物品
	只要他们在隐含因子上表现相似，我们就能为他们推荐相似的内容。这大大提高了模型处理稀疏数据的能力
	分为两种模型：
	1.FunkSVD
 	分成简单的用户和物品特征矩阵
 	![描述](img/abcb1103-7bce-4273-bbdc-58f95ef1a3c0.png)
  	用梯度下降加上L2正则来最小化已知评分的预测误差
	2.BiasSVD
 	为了减小因为用户评分习惯以及物品热度和质量的影响在预测和梯度下降过程中加入偏置项
  	![描述](img/09100b48-44b0-4315-a268-badf941d9ffc.png)
   
总结：协同过滤的缺点在于冷启动，还有主要依赖于用户物品交互数据无法利用其他特征信息

2.向量召回
与协同过滤不同的是使用了向量化技术，可以对用户画像、物品属性等多维数据更有效利用
i2i（Item-to-Item）召回：
一.w2v为每个词学习一个稠密的向量表示，使得语义相近的词在向量空间中距离更近
包括两种模型架构Skip-Gram和CBOW，推荐系统中常用Skip-Gram模型通过给定的中心词来预测其周围的上下文词
	1.Skip-Gram
 	![描述](img/767d56e2-5263-499d-8874-e7191e62111f.png)
  	2.负采样优化
   	第一种方式要计算整个词表，太慢了，所以用负采样来变成二分类，去分类正例和负例就可以
而在推荐系统中，词就是物品，句子就是用户的行为队列
二.i2v直接采用w2v的Skip-Gram架构
三.EGES：用属性信息增强序列
因为i2v无视了用户交互物品的时序信息所以用EGES一是基于会话构建更精细的商品关系图来更好地反映用户行为模式，二是融合商品的辅助信息来解决冷启动问题。
 	1.构建商品关系图
  	设置例如一小时的时间窗口来选取用户的历史行为构建商品关系图，如果两个商品在用户行为序列中连续出现则在它们之间建立一条有向边，边的权重等于商品转移在所有用户行为历史中的频率，这样做更能捕捉用户短期兴趣模式。然后用类似于马尔科夫链的带权随机游走策略生成训练序列
   	![描述](img/1cb35f97-597e-4c3f-8fb5-763731aef7d3.png)
	2.融合辅助信息解决冷启动
 	用EGES来将不同类型的辅助信息的不同的重要性加入到物品的向量化过程中
  	![描述](img/6cc510a5-898b-4e71-b88b-1f6f25c12af0.png)
   	3.也使用了负样本策略
	![描述](img/fbe83f16-8224-4d33-8c59-20a448f55793.png)
四.将业务目标融入序列
有的平台点击率并没有购买率或者说预定率重要，所以设置用户的最终预订行为比简单的点击浏览具有更强的信号强度，来提高促进最终预订，购买转化的推荐
	1.传统的Skip-Gram只有在滑动窗口内的物品才被视为上下文，但是这样并不能捕捉到最终最重要的预定或者购买信号，所以改成最终的目标和每一个浏览过的物品做出正样本对
 	2.由于用户在这个业务中只会在一个地区进行预定，所以负样本从全部物品随机采样改成从同一个地区采样
  	3.冷启动优化根据新物品属性去检索相似的旧物品，使用这些物品向量的均值作为新的向量。

u2i(user-to-item)召回:
核心挑战在于如何在庞大的物品库中找到与用户兴趣高度匹配的候选集
解决的关键在于双塔模型，即物品塔和用户塔，将物品和用户分别编码为向量，然后通过向量间的相似度计算来衡量匹配程度
用户塔：历史行为、人口统计学特征、上下文信息等生成为用户向量
物品塔：物品的ID、类别、属性、内容特征等生成物品向量
这样的优势在于训练完后物品就可以存储到向量数据库里离线计算，只需要实时计算用户向量然后用类似于向量相似度的方法进行召回相似的物品就可以
一.FM（因子分解机）
通过化简以及数学变换最后总结为
![描述](img/61c1e6ee-ab45-4274-8dbc-0a554d34c987.png)
这个公式的分解证明了复杂的这些特征的交互可以分解到两个独立的向量中，然后内积就可以计算匹配分数，证明了双塔结构在推荐系统里的可行性

二.DSSM（深度结构化语义模型）
FM的缺点在于是线性模型，无法处理非线性关系和特征，所以DSSM通过神经网络代替线性变换，从而让物品塔和用户塔分别独立进行后向传播更新参数
DSSM也是将召回任务视为多分类任务，因为物品库过于庞大，所以转而使用负采样技术选取一定量的负样本近似计算。
为了避免原始的向量没有归一化导致使用欧氏距离计算相似度时，距离并不一定在同一个维度，所以对用户塔和物品塔输出的embedding进行L2归一化，同时
相似度计算（归一化后的点积）之后除以温度系数r来控制模型的预测随机度，越小模型预测更加“确定”，不容易产生模糊判断
DSSM的缺点是因为用户塔和物品塔相互独立，两侧特征间的交互信息无法得到充分利用，但是它用可控的精度损失换取了显著的效率提升，为后续更复杂的排序模型留出了计算资源和优化空间。所以我们将它用到召回模块

三.YouTubeDNN
采用了非对称的双塔结构，用户塔包括观看历史、搜索历史、人口统计学特征等多模态信息，用户观看的视频ID通过嵌入层映射后进行平均池化聚合得到用户兴趣向量，模型还引入了“Example Age”特征来建模内容新鲜度的影响，而物品塔极度简单，基本上就是视频id,避免复杂的物品特征工程（不用处理标题、标签、类别等）
将召回任务从预测用户对某个物品的点击概率（或喜欢概率）重新定义为预测下一个观看视频，类似于llm的next token
![描述](img/e7ebdae0-2c86-4954-a874-d606f2e0a2d4.png)
一.传统协同过滤通常随机保留验证数据，如果验证集的数据是用户很早之前看的，而训练集的数据是用户最近看的，就会存在存在未来信息泄露问题，导致像在视频观看这种时序性非常强的任务上预测不准确，所以YouTubeDNN只使用该目标之前的历史行为作为输入特征
二.每次只对数千个负样本进行计算，提升训练速度
三.为每个用户生成固定数量的训练样本，避免高活跃用户主导模型学习,可以很好的提升长尾用户的推荐效果

   	
	 	
	 
	 	
   		
   		
   		
 	



来源：https://datawhalechina.github.io/fun-rec
