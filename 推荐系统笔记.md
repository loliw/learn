第一章：概述
1.每一次推荐都是结合用户，物品，场景的特征去进行预测
**Score = f(User, Item, Context)**
![描述](img/1.png)

工业视角：
2.由于不可能给每个用户进行预测所以推荐系统分成了三层
![描述](img/2.png)
	
 	1.召回：从所有物品库中通过协同过滤等方法粗筛出数量较多的物品
	2.排序：使用模型，也就是上面的公式对召回的候选集的物品进行预测来计算得分
	3.重排：由于排序后可能推荐的物品都是同一类物品，考虑到多样性，新颖性，公平性，对排序适当调整，插入别的物品

宏观视角：
3.工业上完美不代表现实中完美，推荐系统是一个生态，有三个支点：**用户与创作者、内容、平台**

用户与创作者：需要推荐物品的同时也会生产物品
	生产方式分为3类：UGC（普通用户生产，质量参差不齐），PGC（专业用户生产，质量好），AIGC（ai生产，质量）

内容：是推荐系统真正要去分发的物品，不光要发受欢迎的也要分发有潜力的物品

平台：推荐系统的协调者，不光要提升用户满意度，也要维护平台的内容质量，防止标题党
![描述](img/3.png)

召回又分为：
	**协同过滤**
	**向量召回**
	**序列召回**

第二章：召回
1.协同过滤
通过用户的历史行为数据（如评分、点击、购买记录）来计算用户和用户or物品和物品之间的相似度来召回
分为两类：
	一.基于用户（UCF）
 	具有相似历史行为的用户，未来偏好也相似
   	![描述](img/d35ffe5e-2ad4-4c47-af3d-2bec6ea013dc.png)
	实现分为两步：
	1.用户相似度：假设用户u,v分别对应nu,nv
 		杰卡德相似系数:![描述](img/66d865b8-8f38-4e1a-a4cc-47ecd8f5d135.png) 适合只有行为没有评分的数据集
		余弦相似度:![描述](img/fffd7e65-97df-42e0-83f9-772408c31a16.png) 
  		皮尔逊相关系数:![描述](img/034f4a6a-45d1-4b47-a69c-34df9dfbcaad.png) 有评分就用这个
	2.推荐候选物品：
 		简单加权平均：所有用户都计算 
   		考虑评分偏置的版本：减少评分习惯的影响
	 	基于物品倒排表的优化：只计算有交集的用户
	二.基于物品（ICF）
	喜欢某个物品的用户往往也会对相似的物品感兴趣
	![描述](img/5e22c0de-460d-43da-9db0-0164b6ec2290.png)
 	实现也分为两步：
  	1.物品相似度：
   		与用户类似，排除掉无用户交集的物品来计算余弦相似度
	2.推荐候选物品
 		无评分的话就用相似度来计算分数
   		有评分就用皮尔逊相关系数
	特殊的：
	一.swing算法
 	如果多个用户在其他共同购买行为较少的情况下，同时购买了同一对物品，那么这对物品之间的关联性就更可信
  	分为两步：
   	1.构建用户-物品二部图：
		用户与发生过操作的物品进行连线，形成一个连线图
  	2.计算任意一对物品的相似度
   		ui和uj表示与物品ij有过交互的用户集合，iu表示用户u交互过的物品集合
	 	先找到同时与物品ij相连的用户集合ui ∩ uj
   		再对集合中的每一对用户统计其他共同购买的行为，如果其他物品共同购买的行为少的话证明他们在ij上的购买行为更具特异性，从而为ij贡献更高的相似度得分
   		为降低活跃用户对计算结果的影响，引入用户权重
	 	![描述](img/QQ_1758389942289.png)
   	二.Surprise 算法
	这是上面算法的优化，从类别、商品和聚类三个层面来衡量互补相关性：
  	1.类别层面：
   		计算类与类之间的相关性
   		![描述](img/616fdfb2-db3c-4474-9d13-28b280f96414.png)
	2.商品层面：
 		重点考虑两个因素：购买顺序的重要性，时间间隔的影响
   		![描述](img/f018df90-e1a4-40dc-8c6a-634d851ad1a7.png)
	3.聚类层面：
 		用标签传播算法聚类，邻居关系通过Swing算法计算，边权重即为Swing分数
   	4.线性组合：
		把2，3线性组合融合不同层面的信息
  		![描述](img/9bfc76ca-46aa-42a4-8a29-9ae282ba7f59.png)
	二.矩阵分解
	因为协同过滤有时候当评分数据非常稀疏时，很难找到足够的相似用户或物品。所以用矩阵分解
	核心建立于两个假设：
		低秩假设：矩阵可能只受少数几个隐含因素影响，可以降秩
		隐向量假设：可以用一个包含这些隐含因素的向量来表示用户和物品
	只要他们在隐含因子上表现相似，我们就能为他们推荐相似的内容。这大大提高了模型处理稀疏数据的能力
	分为两种模型：
	1.FunkSVD
 	分成简单的用户和物品特征矩阵
 	![描述](img/abcb1103-7bce-4273-bbdc-58f95ef1a3c0.png)
  	用梯度下降加上L2正则来最小化已知评分的预测误差
	2.BiasSVD
 	为了减小因为用户评分习惯以及物品热度和质量的影响在预测和梯度下降过程中加入偏置项
  	![描述](img/09100b48-44b0-4315-a268-badf941d9ffc.png)
   
总结：协同过滤的缺点在于冷启动，还有主要依赖于用户物品交互数据无法利用其他特征信息

2.向量召回
与协同过滤不同的是使用了向量化技术，可以对用户画像、物品属性等多维数据更有效利用
i2i（Item-to-Item）召回：
一.w2v为每个词学习一个稠密的向量表示，使得语义相近的词在向量空间中距离更近
包括两种模型架构Skip-Gram和CBOW，推荐系统中常用Skip-Gram模型通过给定的中心词来预测其周围的上下文词
	1.Skip-Gram
 	![描述](img/767d56e2-5263-499d-8874-e7191e62111f.png)
  	2.负采样优化
   	第一种方式要计算整个词表，太慢了，所以用负采样来变成二分类，去分类正例和负例就可以
而在推荐系统中，词就是物品，句子就是用户的行为队列
二.i2v直接采用w2v的Skip-Gram架构
三.EGES：用属性信息增强序列
因为i2v无视了用户交互物品的时序信息所以用EGES一是基于会话构建更精细的商品关系图来更好地反映用户行为模式，二是融合商品的辅助信息来解决冷启动问题。
 	1.构建商品关系图
  	设置例如一小时的时间窗口来选取用户的历史行为构建商品关系图，如果两个商品在用户行为序列中连续出现则在它们之间建立一条有向边，边的权重等于商品转移在所有用户行为历史中的频率，这样做更能捕捉用户短期兴趣模式。然后用类似于马尔科夫链的带权随机游走策略生成训练序列
   	![描述](img/1cb35f97-597e-4c3f-8fb5-763731aef7d3.png)
	2.融合辅助信息解决冷启动
 	用EGES来将不同类型的辅助信息的不同的重要性加入到物品的向量化过程中
  	![描述](img/6cc510a5-898b-4e71-b88b-1f6f25c12af0.png)
   	3.也使用了负样本策略
	![描述](img/fbe83f16-8224-4d33-8c59-20a448f55793.png)
四.将业务目标融入序列
有的平台点击率并没有购买率或者说预定率重要，所以设置用户的最终预订行为比简单的点击浏览具有更强的信号强度，来提高促进最终预订，购买转化的推荐
	1.传统的Skip-Gram只有在滑动窗口内的物品才被视为上下文，但是这样并不能捕捉到最终最重要的预定或者购买信号，所以改成最终的目标和每一个浏览过的物品做出正样本对
 	2.由于用户在这个业务中只会在一个地区进行预定，所以负样本从全部物品随机采样改成从同一个地区采样
  	3.冷启动优化根据新物品属性去检索相似的旧物品，使用这些物品向量的均值作为新的向量。


   	
	 	
	 
	 	
   		
   		
   		
 	



来源：https://datawhalechina.github.io/fun-rec
