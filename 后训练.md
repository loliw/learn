后训练是在预训练的基础上开展的，用来从精心筛选的数据中学习响应模式
预训练通常为无监督学习，而后训练分为3种方法：
1.sft
2.dpo
3.onlinerl

而并非所有场景都需要后训练
1.仅需遵循少量指令的话，直接通过提示词过程（不稳定）
2.查询实时数据
3.创建领域专用模型，要先基于至少10亿进行预训练
当需要严格遵循20条以上指令，或提升特定能力（如构建强SQL模型、函数调用模型或推理模型）时，后训练最能发挥价值——它能可靠改变模型行为并提升目标能力，但若实施不当可能导致其他未训练能力退化

1.sft适合的场景
激发新的模型行为：
将预训练模型转变为能遵循指令的助理。
让不具备推理能力的模型学会基本推理。
让模型在没有明确说明的情况下使用特定工具。
提升模型能力：
利用强大的大模型生成高质量的合成数据，通过训练把这些能力“蒸馏”到小模型中。

数据质量比数量更重要，常用的数据策划方法包括：
1.蒸馏：用大的模型生成回复，去训练小模型
2.拒绝采样：针对一个提问生成多个候选回复，然后用奖励函数选择最好的一个
3.过滤：从开源大型sft数据集中挑选质量高多样性好的样本

微调又分为全参和lora微调，lora更省资源


以下为一个可复用的推理函数：
def generate_responses(model, tokenizer, user_message, system_message=None,
                       max_new_tokens=100):
    # 将输入的 prompt 使用 chat message
    messages = []
    if system_message:
        messages.append({"role": "system", "content": system_message})

    # 假设所有的数据都是单轮对话（Q-A）
    messages.append({"role": "user", "content": user_message})

    prompt = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=False,
    )

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
    input_len = inputs["input_ids"].shape[1]
    generated_ids = outputs[0][input_len:]
    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()

    return response

使用AutoTokenizer.from_pretrained()和AutoModelForCausalLM.from_pretrained()可以用来加载模型和分词器

tokenizer.chat_template = """{% for message in messages %}
                {% if message['role'] == 'system' %}System: {{ message['content'] }}\n
                {% elif message['role'] == 'user' %}User: {{ message['content'] }}\n
                {% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }} <|endoftext|>
                {% endif %}
                {% endfor %}"""

上面是一个分词器的模板

tokenizer.pad_token = tokenizer.eos_token

而这是把填充token设为eos

可以用下面的代码来设置sft参数
sft_config = SFTConfig(
    learning_rate=8e-5,
    num_train_epochs=1,
    per_device_train_batch_size=1, # 每块 GPU 的 batch size。
    gradient_accumulation_steps=8, # 梯度累积次数。
    gradient_checkpointing=False, # 启用梯度检查点机制，以降低训练期间的内存使用量，但会以训练速度变慢为代价。
    logging_steps=2,  # 每两个 step 打印一次 log。
)

sft_trainer = SFTTrainer(
    model=model,
    args=sft_config,
    train_dataset=train_dataset,
    processing_class=tokenizer,
)
sft_trainer.train()

像上面这样输入到SFTTrainer就可以开始训练了
