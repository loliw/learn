后训练是在预训练的基础上开展的，用来从精心筛选的数据中学习响应模式
预训练通常为无监督学习，而后训练分为3种方法：
1.sft
2.dpo
3.onlinerl

而并非所有场景都需要后训练
1.仅需遵循少量指令的话，直接通过提示词过程（不稳定）
2.查询实时数据
3.创建领域专用模型，要先基于至少10亿进行预训练
当需要严格遵循20条以上指令，或提升特定能力（如构建强SQL模型、函数调用模型或推理模型）时，后训练最能发挥价值——它能可靠改变模型行为并提升目标能力，但若实施不当可能导致其他未训练能力退化

1.sft适合的场景
激发新的模型行为：
将预训练模型转变为能遵循指令的助理。
让不具备推理能力的模型学会基本推理。
让模型在没有明确说明的情况下使用特定工具。
提升模型能力：
利用强大的大模型生成高质量的合成数据，通过训练把这些能力“蒸馏”到小模型中。

数据质量比数量更重要，常用的数据策划方法包括：
1.蒸馏：用大的模型生成回复，去训练小模型
2.拒绝采样：针对一个提问生成多个候选回复，然后用奖励函数选择最好的一个
3.过滤：从开源大型sft数据集中挑选质量高多样性好的样本

微调又分为全参和lora微调，lora更省资源
